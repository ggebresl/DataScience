{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.request is a Python module for fetching URLs - using urlopen function\n",
    "## Installing urllib --> pip install urllib \n",
    "\n",
    "## import urllib.request with \n",
    "## urllib.request.urlopen(' https://www.w3schools.com/') as response:   \n",
    "## html = response.read() \n",
    "\n",
    "## steps\n",
    "## Creating url request using \n",
    "## urllib.request.Request() \n",
    "\n",
    "## Calling urllib.request.urlopen() \n",
    "## with this Request object returns a response object for the URL requested. \n",
    "\n",
    "## This response is a file-like object, which means you can for example call .read() on the response \n",
    "\n",
    "## Sending Data along with URL: Methods to send data Post(..) and Get(..)\n",
    "## Url Encoding - urllib.parse. Used to encode the data before sending\n",
    "## Using POST\n",
    "\n",
    "## Sending Data along with URL using Post\n",
    "\n",
    "## import urllib.parse  \n",
    "## import urllib.request  \n",
    "## url = 'http://www.someserver.com/cgi-bin/register.cgi'\n",
    "## values = {'name' : 'Michael Foord', 'location' : 'Northampton', 'language' : 'Python' } \n",
    "## data = urllib.parse.urlencode(values)\n",
    "## data = data.encode('ascii')  #’utf-8’ \n",
    "## data should be bytes  \n",
    "\n",
    "## req = urllib.request.Request(url, data)  \n",
    "## with urllib.request.urlopen(req) as response:   \n",
    "## \tthe_page = response.read() \n",
    "\n",
    "## Sending data along with URL using Get\n",
    "\n",
    "## import urllib.request  \n",
    "## import urllib.parse  \n",
    " \n",
    "## data = {}  \n",
    "## data['name'] = 'Somebody Here'  \n",
    "## data['location'] = 'Northampton'  \n",
    "## data['language'] = 'Python‘ \n",
    "\n",
    "## url_values = urllib.parse.urlencode(data)  \n",
    "## print(url_values) \n",
    "\n",
    "## url = 'http://www.example.com/example.cgi'  \n",
    "## full_url = url + '?' + url_values  \n",
    "\n",
    "## data = urllib.request.urlopen(full_url) \n",
    "\n",
    "\n",
    "## handling Exeptions\n",
    "## urlopen raises URLError when it cannot handle a response \n",
    "## URLError:\n",
    "\n",
    "## req = urllib.request.Request('http://www.pretend_server.org')  \n",
    "## try: urllib.request.urlopen(req)\n",
    "\n",
    "## except urllib.error.URLError as e:\n",
    "## print(e.reason)  \n",
    "\n",
    "## HTTPError \n",
    "\n",
    "## from urllib.request import Request, urlopen  \n",
    "## from urllib.error import URLError  \n",
    "\n",
    "## req = Request(someurl)  \n",
    "## try:\n",
    "##   response = urlopen(req)  \n",
    "## except URLError as e:   \n",
    "## if hasattr(e, 'reason'):  \n",
    "##    print('We failed to reach a server.')  \n",
    "##    print('Reason: ', e.reason)  \n",
    "## elif hasattr(e, 'code'):  \n",
    "##     print('The server couldn\\'t fulfill the request.') \n",
    "##     print('Error code: ', e.code)   \n",
    "##  else:\n",
    "##     # everything is fine \n",
    "\n",
    "\n",
    "## info and ged geturl\n",
    "## The response returned by urlopen as two useful methods info() and geturl() \n",
    "## geturl - this returns the real URL of the page fetched\n",
    "\n",
    "## info - this returns a dictionary-like object that describes the page fetched. (header information) \n",
    "\n",
    "## Using Regular Expression Module\n",
    "\n",
    "## re.findall(r’<requered-pattern>’, inputstring) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractBasicAuthHandler',\n",
       " 'AbstractDigestAuthHandler',\n",
       " 'AbstractHTTPHandler',\n",
       " 'BaseHandler',\n",
       " 'CacheFTPHandler',\n",
       " 'ContentTooShortError',\n",
       " 'DataHandler',\n",
       " 'FTPHandler',\n",
       " 'FancyURLopener',\n",
       " 'FileHandler',\n",
       " 'HTTPBasicAuthHandler',\n",
       " 'HTTPCookieProcessor',\n",
       " 'HTTPDefaultErrorHandler',\n",
       " 'HTTPDigestAuthHandler',\n",
       " 'HTTPError',\n",
       " 'HTTPErrorProcessor',\n",
       " 'HTTPHandler',\n",
       " 'HTTPPasswordMgr',\n",
       " 'HTTPPasswordMgrWithDefaultRealm',\n",
       " 'HTTPPasswordMgrWithPriorAuth',\n",
       " 'HTTPRedirectHandler',\n",
       " 'HTTPSHandler',\n",
       " 'MAXFTPCACHE',\n",
       " 'OpenerDirector',\n",
       " 'ProxyBasicAuthHandler',\n",
       " 'ProxyDigestAuthHandler',\n",
       " 'ProxyHandler',\n",
       " 'Request',\n",
       " 'URLError',\n",
       " 'URLopener',\n",
       " 'UnknownHandler',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_cut_port_re',\n",
       " '_ftperrors',\n",
       " '_have_ssl',\n",
       " '_localhost',\n",
       " '_noheaders',\n",
       " '_opener',\n",
       " '_parse_proxy',\n",
       " '_proxy_bypass_macosx_sysconf',\n",
       " '_randombytes',\n",
       " '_safe_gethostbyname',\n",
       " '_thishost',\n",
       " '_url_tempfiles',\n",
       " 'addclosehook',\n",
       " 'addinfourl',\n",
       " 'base64',\n",
       " 'bisect',\n",
       " 'build_opener',\n",
       " 'contextlib',\n",
       " 'email',\n",
       " 'ftpcache',\n",
       " 'ftperrors',\n",
       " 'ftpwrapper',\n",
       " 'getproxies',\n",
       " 'getproxies_environment',\n",
       " 'getproxies_registry',\n",
       " 'hashlib',\n",
       " 'http',\n",
       " 'install_opener',\n",
       " 'io',\n",
       " 'localhost',\n",
       " 'noheaders',\n",
       " 'os',\n",
       " 'parse_http_list',\n",
       " 'parse_keqv_list',\n",
       " 'pathname2url',\n",
       " 'posixpath',\n",
       " 'proxy_bypass',\n",
       " 'proxy_bypass_environment',\n",
       " 'proxy_bypass_registry',\n",
       " 'quote',\n",
       " 're',\n",
       " 'request_host',\n",
       " 'socket',\n",
       " 'splitattr',\n",
       " 'splithost',\n",
       " 'splitpasswd',\n",
       " 'splitport',\n",
       " 'splitquery',\n",
       " 'splittag',\n",
       " 'splittype',\n",
       " 'splituser',\n",
       " 'splitvalue',\n",
       " 'ssl',\n",
       " 'string',\n",
       " 'sys',\n",
       " 'tempfile',\n",
       " 'thishost',\n",
       " 'time',\n",
       " 'to_bytes',\n",
       " 'unquote',\n",
       " 'unquote_to_bytes',\n",
       " 'unwrap',\n",
       " 'url2pathname',\n",
       " 'urlcleanup',\n",
       " 'urljoin',\n",
       " 'urlopen',\n",
       " 'urlparse',\n",
       " 'urlretrieve',\n",
       " 'urlsplit',\n",
       " 'urlunparse',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(urllib.request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = urllib.request.urlopen('http://wwww.w3Schools.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html><head><meta http-equiv=\"refresh\" content=\"0;url=http://searchassist.verizon.com/main?ParticipantID=euekiz39ksg8nwp7iqj2fp5wzfwi5q76&FailedURI=http%3A%2F%2Fwwww.w3Schools.com%2F&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\"/><script type=\"text/javascript\">url=\"http://searchassist.verizon.com/main?ParticipantID=euekiz39ksg8nwp7iqj2fp5wzfwi5q76&FailedURI=http%3A%2F%2Fwwww.w3Schools.com%2F&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\";if(top.location!=location){var w=window,d=document,e=d.documentElement,b=d.body,x=w.innerWidth||e.clientWidth||b.clientWidth,y=w.innerHeight||e.clientHeight||b.clientHeight;url+=\"&w=\"+x+\"&h=\"+y;}window.location.replace(url);</script></head><body></body></html>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.pythonprogramming.net'\n",
    "values = {'s':'basic', 'submit': 'search'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = url.parse.urlencode(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ggebr\\anaconda3\\lib\\site-packages (from bs4) (4.6.3)\n",
      "Building wheels for collected packages: bs4\n",
      "  Running setup.py bdist_wheel for bs4: started\n",
      "  Running setup.py bdist_wheel for bs4: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\ggebr\\AppData\\Local\\pip\\Cache\\wheels\\a0\\b0\\b2\\4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install from b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n",
    "source = urllib.request.urlopen('https://pythonprogramming.net/parsememcparseface/').read()\n",
    "soup = bs.BeautifulSoup(source, 'lxml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Python Programming Tutorials</title>\n",
      "title\n",
      "Python Programming Tutorials\n",
      "<p class=\"introduction\">Oh, hello! This is a <span style=\"font-size:115%\">wonderful</span> page meant to let you practice web scraping. This page was originally created to help people work with the <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" target=\"blank\"><strong>Beautiful Soup 4</strong></a> library.</p>\n",
      "<p class=\"introduction\">Oh, hello! This is a <span style=\"font-size:115%\">wonderful</span> page meant to let you practice web scraping. This page was originally created to help people work with the <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" target=\"blank\"><strong>Beautiful Soup 4</strong></a> library.</p>\n",
      "<p>The following table gives some general information for the following <code>programming languages</code>:</p>\n",
      "<p>I think it's clear that, on a scale of 1-10, python is:</p>\n",
      "<p>Javascript (dynamic data) test:</p>\n",
      "<p class=\"jstest\" id=\"yesnojs\">y u bad tho?</p>\n",
      "<p>Whᶐt hαppéns now¿</p>\n",
      "<p><a href=\"/sitemap.xml\" target=\"blank\"><strong>sitemap</strong></a></p>\n",
      "<p class=\"grey-text text-lighten-4\">Contact: Harrison@pythonprogramming.net.</p>\n",
      "<p class=\"grey-text right\" style=\"padding-right:10px\">Programming is a superpower.</p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.name)\n",
    "print(soup.title.string)\n",
    "print(soup.p)\n",
    "\n",
    "#print(soup.find_all('p'))\n",
    "for par in soup.find_all('p'):\n",
    "    print(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
