{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89 56 34 76 89 98]\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = [89,56, 34, 76,89, 98] \n",
    "first_arr =np.array(scores) \n",
    "\n",
    "print(first_arr) \n",
    "print(first_arr.dtype) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested lists with equal length, will be converted into a multidimensional array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1 = [[34,56,23,89], [11,45,76,34]] \n",
    "second_arr = np.array(scores_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 56 23 89]\n",
      " [11 45 76 34]]\n"
     ]
    }
   ],
   "source": [
    "print(second_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(2, 4)\n",
      "int32\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(second_arr.ndim) # 2\n",
    "print(second_arr.shape) # (2, 4)\n",
    "print(second_arr.dtype) #int32\n",
    "\n",
    "x = np.zeros(10) \n",
    "print(x) \n",
    "t = np.ones(10)\n",
    "print(t)\n",
    "\n",
    "y=np.zeros((4,3)) \n",
    "\n",
    "print(y) \n",
    " \n",
    "np.arange(15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a square N x N identity matrix (1’s on the diagonal and 0’s elsewhere) Batch operations on data can be performed without using for loops, this is called vectorizaton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.   56.34 76.   89.   98.  ]\n",
      "[7921.     3174.1956 5776.     7921.     9604.    ]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0.01123596 0.01774938 0.01315789 0.01123596 0.01020408]\n",
      "[9.43398113 7.5059976  8.71779789 9.43398113 9.89949494]\n"
     ]
    }
   ],
   "source": [
    "np.eye(6) \n",
    "\n",
    "scores = [89,56.34, 76,89, 98] \n",
    "first_arr =np.array(scores)\n",
    "\n",
    "print (first_arr) \n",
    "print (first_arr * first_arr) \n",
    "print (first_arr - first_arr) \n",
    "print (1/(first_arr)) \n",
    "print (first_arr ** 0.5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing.  you may want to select a subset of your data, for which Numpy array indexing is really useful  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6 7 8]\n",
      "[ 0  1  2  3 99 99 99 99 99  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "new_arr = np.arange(12)  \n",
    "print (new_arr[4:9]) #[4 5 6 7 8]\n",
    "\n",
    "new_arr[4:9] = 99\n",
    "print(new_arr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arrays can be treated like matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4 5]\n",
      " [6 7 8]\n",
      " [9 5 1]]\n",
      "[6 7 8]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "matrix_arr =np.array([[3,4,5],[6,7,8],[9,5,1]]) \n",
    "\n",
    "print (matrix_arr) \n",
    " \n",
    "print (matrix_arr[0][2]) #first row and third column print (matrix_arr[0,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 8]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print (matrix_arr[1])\n",
    "print (matrix_arr[0][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d arrays -> this is a 2x2x3 array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "returns the second list inside first list [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "three_d_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]) \n",
    "\n",
    "print (three_d_arr) \n",
    "\n",
    "print (\"returns the second list inside first list {}\".format(three_d_arr[0,1])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n"
     ]
    }
   ],
   "source": [
    "print(three_d_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing using Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5 -4 -3 -2 -1  0  1  2  3  4]\n"
     ]
    }
   ],
   "source": [
    "mtrices = np.arange(-5,5,1) \n",
    "print(mtrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(mtrices, mtrices)) #mesh grid function takes two 1 d arrays and produces two 2d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
      " [-5 -4 -3 -2 -1  0  1  2  3  4]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5 -5 -5 -5 -5 -5 -5 -5 -5 -5]\n",
      " [-4 -4 -4 -4 -4 -4 -4 -4 -4 -4]\n",
      " [-3 -3 -3 -3 -3 -3 -3 -3 -3 -3]\n",
      " [-2 -2 -2 -2 -2 -2 -2 -2 -2 -2]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 2  2  2  2  2  2  2  2  2  2]\n",
      " [ 3  3  3  3  3  3  3  3  3  3]\n",
      " [ 4  4  4  4  4  4  4  4  4  4]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series. A Series is represented by index on the left and values on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    5\n",
      "b    4\n",
      "c    3\n",
      "d    2\n",
      "e    1\n",
      "dtype: int64\n",
      "Rooney        50000\n",
      "Messi         75000\n",
      "Ronaldo       85000\n",
      "Fabregas      40000\n",
      "Van persie    67000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "mjp = Series([5,4,3,2,1])\n",
    "mjp.values # Similar to dictionary. values command return values in a series\n",
    "\n",
    "ser = Series([5,4,3,2,1,-7,-29], index=['a','b','c','d','e','f','h']) # The index is specified\n",
    "\n",
    "print(ser[ser > 0]) #Returns only the positive values\n",
    "np.mean(ser) # you can apply numpy functions to a Serives\n",
    "\n",
    "\n",
    "player_salary ={'Rooney': 50000, 'Messi': 75000, 'Ronaldo': 85000, 'Fabregas':40000, 'Van persie': 67000}  \n",
    "player_salary\n",
    "\n",
    "new_player = Series(player_salary)  # converting a dictionary to a series \n",
    "print(new_player)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Frame \n",
    "Data frame is a spread sheet like structure, containing ordered collection of columns. Each column can have different value type. Data frame has both row index and column index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Language</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Gujarati</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Kannada</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State   Language  Population\n",
       "0     Gujarat   Gujarati          36\n",
       "1  Tamil Nadu      Tamil          44\n",
       "2      Andhra     Telugu          67\n",
       "3   Karnataka    Kannada          89\n",
       "4      Kerala  Malayalam          34"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = {'State' :['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'], \n",
    "                  'Population': [36, 44, 67,89,34], \n",
    "                  'Language' :['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']} \n",
    "\n",
    "\n",
    "\n",
    "india = DataFrame(states)   # creating a data frame print(india) \n",
    "\n",
    "DataFrame(states, columns=['State', 'Language', 'Population'])  # change the sequence of column index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State   Language  Population Per Capita Income\n",
      "a     Gujarat   Gujarati          36               NaN\n",
      "b  Tamil Nadu      Tamil          44               NaN\n",
      "c      Andhra     Telugu          67               NaN\n",
      "d   Karnataka    Kannada          89               NaN\n",
      "e      Kerala  Malayalam          34               NaN\n"
     ]
    }
   ],
   "source": [
    "new_farme = DataFrame(states, columns=['State', 'Language', 'Population', 'Per Capita Income'], index =['a','b','c','d','e']) \n",
    "print(new_farme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    36\n",
      "b    44\n",
      "c    67\n",
      "d    89\n",
      "e    34\n",
      "Name: Population, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_farme.Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Modi  Rahul\n",
      "2010    72     55\n",
      "2012    78     34\n",
      "2014    98     22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modi</th>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rahul</th>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2010  2012  2014\n",
       "Modi     72    78    98\n",
       "Rahul    55    34    22"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data ={'Modi': {2010: 72, 2012: 78, 2014 : 98},'Rahul': {2010: 55, 2012: 34, 2014: 22}} \n",
    "elections = DataFrame(new_data)  \n",
    "print(elections)  # the outer dict keys are columns and inner dict keys are rows elections.T   # transpose of a data frame inner dict keys are rows \n",
    "elections.T   # transpose of a data frame \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping entries from an axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'State': ['Gujarat', 'Tamil Nadu', ' Andhra', 'Karnataka', 'Kerala'], 'Population': [36, 44, 67, 89, 34], 'Language': ['Gujarati', 'Tamil', 'Telugu', 'Kannada', 'Malayalam']}\n",
      "        State  Population   Language\n",
      "0     Gujarat          36   Gujarati\n",
      "1  Tamil Nadu          44      Tamil\n",
      "2      Andhra          67     Telugu\n",
      "3   Karnataka          89    Kannada\n",
      "4      Kerala          34  Malayalam\n",
      "        State   Language  Population Per Capita Income\n",
      "a     Gujarat   Gujarati          36               NaN\n",
      "b  Tamil Nadu      Tamil          44               NaN\n",
      "c      Andhra     Telugu          67               NaN\n",
      "d   Karnataka    Kannada          89               NaN\n",
      "e      Kerala  Malayalam          34               NaN\n"
     ]
    }
   ],
   "source": [
    "print(states)\n",
    "print(india)\n",
    "states.values\n",
    "print(new_farme)\n",
    "new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mungling Basics\n",
    "## Segment 1 - Filtering and Selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and retrieving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 1    0\n",
      "row 2    1\n",
      "row 3    2\n",
      "row 4    3\n",
      "row 5    4\n",
      "row 6    5\n",
      "row 7    6\n",
      "row 8    7\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "series_obj = Series(np.arange(8), index=['row 1', 'row 2','row 3','row 4','row 5', 'row 6', 'row 7', 'row 8']) \n",
    "print(series_obj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When you write square brackets with an integer index inside them, this tells Python to select and retrieve all records with the specified integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 1    0\n",
      "row 3    2\n",
      "row 5    4\n",
      "row 8    7\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(series_obj[[0,2,4,7]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25) \n",
    "DF_obj = DataFrame(np.random.rand(36).reshape((6,6)),\n",
    "                   index=['row 1', 'row 2', 'row 3', 'row 4', 'row 5', 'row 6'],                    \n",
    "                   columns=['column 1', 'column 2', 'column 3', 'column 4', 'column 5', 'column 6']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       column 1  column 2  column 3  column 4  column 5  column 6\n",
      "row 1  0.870124  0.582277  0.278839  0.185911  0.411100  0.117376\n",
      "row 2  0.684969  0.437611  0.556229  0.367080  0.402366  0.113041\n",
      "row 3  0.447031  0.585445  0.161985  0.520719  0.326051  0.699186\n",
      "row 4  0.366395  0.836375  0.481343  0.516502  0.383048  0.997541\n",
      "row 5  0.514244  0.559053  0.034450  0.719930  0.421004  0.436935\n",
      "row 6  0.281701  0.900274  0.669612  0.456069  0.289804  0.525819\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you call the .ix[] special indexer, and pass in a set of row and column indexes, this tells Python to select and retrieve only those specific rows and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column 5</th>\n",
       "      <th>column 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row 2</th>\n",
       "      <td>0.402366</td>\n",
       "      <td>0.437611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row 5</th>\n",
       "      <td>0.421004</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column 5  column 2\n",
       "row 2  0.402366  0.437611\n",
       "row 5  0.421004  0.559053"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_obj.loc[['row 2', 'row 5'], ['column 5', 'column 2']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data slicing -> ['starting label-index':'ending label-index']  \n",
    "##### Data slicing allows you to select and retrieve all records from the starting label-index, to the  # ending label-index, and every record in between. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       column 1  column 2  column 3  column 4  column 5  column 6\n",
      "row 3  0.447031  0.585445  0.161985  0.520719  0.326051  0.699186\n",
      "row 4  0.366395  0.836375  0.481343  0.516502  0.383048  0.997541\n",
      "row 5  0.514244  0.559053  0.034450  0.719930  0.421004  0.436935\n",
      "row 6  0.281701  0.900274  0.669612  0.456069  0.289804  0.525819\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj['row 3':'row 7']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 2 - Treating missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "from pandas import Series, DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out what data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    row 1\n",
      "1    row 2\n",
      "2      NaN\n",
      "3    row 4\n",
      "4    row 5\n",
      "5    row 6\n",
      "6      NaN\n",
      "7    row 8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "missing = np.nan \n",
    "series_obj = Series(['row 1', 'row 2', missing, 'row 4','row 5', 'row 6', missing, 'row 8']) \n",
    "\n",
    "print(series_obj) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The isnull() method returns a Boolean value that describes (True or False) whether an element in a Pandas object is a null value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(series_obj.isnull()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723 -0.169196\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258 -0.539484\n",
      "3  0.529918  0.382797  1.800623  2.513618 -0.245011  0.208728\n",
      "4 -0.300852  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DF_obj = DataFrame(np.random.randn(36).reshape(6,6)) \n",
    "print(DF_obj) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723       NaN\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258       NaN\n",
      "3       NaN  0.382797  1.800623  2.513618 -0.245011       NaN\n",
      "4       NaN  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "DF_obj.iloc[3:5, 0] = missing \n",
    "\n",
    "DF_obj.iloc[1:4, 5] = missing \n",
    "\n",
    "print(DF_obj) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fillna method() finds each missing value from within a Pandas object and fills it with the  # numeric value that you've passed in using: object_name.fillna(numeric value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723  0.000000\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258  0.000000\n",
      "3  0.000000  0.382797  1.800623  2.513618 -0.245011  0.000000\n",
      "4  0.000000  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "filled_DF = DF_obj.fillna(0)\n",
    "print(filled_DF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723       NaN\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258       NaN\n",
      "3       NaN  0.382797  1.800623  2.513618 -0.245011       NaN\n",
      "4       NaN  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can pass a dictionary into the .fillna() method. The method will then fill in missing values from each column Series (as designated by the dictionary key) with its own unique value (as specified in the corresponding dictionary value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723  1.250000\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258  1.250000\n",
      "3  0.100000  0.382797  1.800623  2.513618 -0.245011  1.250000\n",
      "4  0.100000  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "filled_DF = DF_obj.fillna({0: 0.1, 5: 1.25}) \n",
    "print(filled_DF) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also pass in the method='ffill' arguement, and the .fillna() method will fill-forward any  # missing values with values from the last non-null element in the column Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723       NaN\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258       NaN\n",
      "3       NaN  0.382797  1.800623  2.513618 -0.245011       NaN\n",
      "4       NaN  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n",
      "          0         1         2         3         4         5\n",
      "0  1.020364 -0.587397  0.048037  0.560169  1.424193 -0.003191\n",
      "1 -0.297766  0.232724  0.671954 -1.346282 -0.601723 -0.003191\n",
      "2 -0.658381 -0.196024  0.177552  0.032294  1.303258 -0.003191\n",
      "3 -0.658381  0.382797  1.800623  2.513618 -0.245011 -0.003191\n",
      "4 -0.658381  0.152992  0.030979 -0.324954 -0.777273 -0.337442\n",
      "5 -2.020510  1.419771 -0.741890 -1.559918  0.966290 -0.182294\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj)\n",
    "fill_DF = DF_obj.fillna(method='ffill') \n",
    "print(fill_DF) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.164135 -0.673210 -0.168668 -0.541845 -0.352464  1.688785\n",
      "1  0.092362  1.121011 -0.451224  0.872053 -1.142141       NaN\n",
      "2  0.930692 -0.177927 -2.158403 -0.289260 -0.904782       NaN\n",
      "3       NaN  0.649388  0.019125 -0.977803 -1.972866       NaN\n",
      "4       NaN -3.049890  0.394720 -1.947339  0.533330  0.379163\n",
      "5  2.040071  0.307235 -0.669187 -0.196576  0.922861  1.727249\n"
     ]
    }
   ],
   "source": [
    "DF_obj = DataFrame(np.random.randn(36).reshape(6,6)) \n",
    "\n",
    "DF_obj.iloc[3:5, 0] = missing \n",
    "DF_obj.iloc[1:4, 5] = missing \n",
    "print(DF_obj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To generate a count of how many missing values a DataFrame has per column, just call the .isnull() method off of the object, and then call the .sum() method off of the matrix of Boolean values it returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_obj.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out missing values. \n",
    "### To identify and drop all rows from a DataFrame that contain ANY missing values, simply call the .dropna() method off of the DataFrame object. NOTE: If you wanted to drop columns that contain any missing values, you'd just pass in the axis=1 argument to select and search the DataFrame by columns, instead of by row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.164135 -0.673210 -0.168668 -0.541845 -0.352464  1.688785\n",
      "1  0.092362  1.121011 -0.451224  0.872053 -1.142141       NaN\n",
      "2  0.930692 -0.177927 -2.158403 -0.289260 -0.904782       NaN\n",
      "3       NaN  0.649388  0.019125 -0.977803 -1.972866       NaN\n",
      "4       NaN -3.049890  0.394720 -1.947339  0.533330  0.379163\n",
      "5  2.040071  0.307235 -0.669187 -0.196576  0.922861  1.727249\n",
      "          1         2         3         4\n",
      "0 -0.673210 -0.168668 -0.541845 -0.352464\n",
      "1  1.121011 -0.451224  0.872053 -1.142141\n",
      "2 -0.177927 -2.158403 -0.289260 -0.904782\n",
      "3  0.649388  0.019125 -0.977803 -1.972866\n",
      "4 -3.049890  0.394720 -1.947339  0.533330\n",
      "5  0.307235 -0.669187 -0.196576  0.922861\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj) \n",
    "DF_no_NaN = DF_obj.dropna(axis=1)\n",
    "\n",
    "print(DF_no_NaN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To identify and drop only the rows from a DataFrame that contain ALL missing values, simply call the .dropna() method off of the DataFrame object, and pass in the how='all' argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.164135 -0.673210 -0.168668 -0.541845 -0.352464  1.688785\n",
      "1  0.092362  1.121011 -0.451224  0.872053 -1.142141       NaN\n",
      "2  0.930692 -0.177927 -2.158403 -0.289260 -0.904782       NaN\n",
      "3       NaN  0.649388  0.019125 -0.977803 -1.972866       NaN\n",
      "4       NaN -3.049890  0.394720 -1.947339  0.533330  0.379163\n",
      "5  2.040071  0.307235 -0.669187 -0.196576  0.922861  1.727249\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.164135 -0.673210 -0.168668 -0.541845 -0.352464  1.688785\n",
      "1  0.092362  1.121011 -0.451224  0.872053 -1.142141       NaN\n",
      "2  0.930692 -0.177927 -2.158403 -0.289260 -0.904782       NaN\n",
      "3       NaN  0.649388  0.019125 -0.977803 -1.972866       NaN\n",
      "4       NaN -3.049890  0.394720 -1.947339  0.533330  0.379163\n",
      "5  2.040071  0.307235 -0.669187 -0.196576  0.922861  1.727249\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj.dropna(how='all')) \n",
    "dropall = DF_obj.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5\n",
      "0  0.164135 -0.673210 -0.168668 -0.541845 -0.352464  1.688785\n",
      "1  0.092362  1.121011 -0.451224  0.872053 -1.142141       NaN\n",
      "2  0.930692 -0.177927 -2.158403 -0.289260 -0.904782       NaN\n",
      "3       NaN  0.649388  0.019125 -0.977803 -1.972866       NaN\n",
      "4       NaN -3.049890  0.394720 -1.947339  0.533330  0.379163\n",
      "5  2.040071  0.307235 -0.669187 -0.196576  0.922861  1.727249\n"
     ]
    }
   ],
   "source": [
    "print(dropall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment 3 - Removing duplicates. This is for both column and nows as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas import Series, DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "1         1        a        A\n",
      "2         2        b        B\n",
      "3         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        C\n",
      "6         3        c        C\n"
     ]
    }
   ],
   "source": [
    "DF_obj1 = DataFrame({'column 1': [1, 1, 2, 2, 3, 3, 3], \n",
    "                     'column 2': ['a', 'a', 'b', 'b', 'c', 'c', 'c'],                   \n",
    "                     'column 3': ['A', 'A', 'B', 'B', 'C', 'C', 'C']})\n",
    "\n",
    "print(DF_obj1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The duplicated() method searches each row in the DataFrame, and returns a True or False value to indicate whether it is a duplicate of another row found earlier in the DataFrame. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To drop all duplicate rows, just call the drop_duplicates() method off of the DataFrame. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "2         2        b        B\n",
      "4         3        c        C\n"
     ]
    }
   ],
   "source": [
    "dup =  DF_obj1.drop_duplicates()\n",
    "print(dup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "1         1        a        A\n",
      "2         2        b        B\n",
      "3         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        C\n",
      "6         3        c        C\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "1         1        a        A\n",
      "2         2        b        B\n",
      "3         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        D\n",
      "6         3        c        C\n"
     ]
    }
   ],
   "source": [
    "DF_obj2 = DataFrame({'column 1': [1, 1, 2, 2, 3, 3, 3], \n",
    "                     'column 2': ['a', 'a', 'b', 'b', 'c', 'c', 'c'], \n",
    "                     'column 3': ['A', 'A', 'B', 'B', 'C', 'D', 'C']}) \n",
    "\n",
    "print(DF_obj2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To drop the rows that have duplicates in only one column Series, just call the drop_duplicates() method of the DataFrame, and pass in the label-index of the column you want the de-duplication to be based on. This method will drops all rows that have duplicates in the column you specify. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "1         1        a        A\n",
      "2         2        b        B\n",
      "3         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        D\n",
      "6         3        c        C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dup2 = DF_obj2.drop_duplicates(['column 3'])\n",
    "print(DF_obj2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "2         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        D\n"
     ]
    }
   ],
   "source": [
    "print(dup2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating and transforming data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n"
     ]
    }
   ],
   "source": [
    "DF_obj3 = pd.DataFrame(np.arange(36).reshape(6,6))\n",
    "print(DF_obj3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2\n",
      "0   0   1   2\n",
      "1   3   4   5\n",
      "2   6   7   8\n",
      "3   9  10  11\n",
      "4  12  13  14\n"
     ]
    }
   ],
   "source": [
    "DF_obj_4 = pd.DataFrame(np.arange(15).reshape(5,3)) \n",
    "print(DF_obj_4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating data --->pd.concat([left_object, right_object], axis=1) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The concat() method joins data from seperate sources into one combined data table. If you want to join objects based on their row index values, just call the pd.concat() method on the objects you want joined, and then pass in the axis=1 argument. The axis=1 argument tells Python to concatenate the DataFrames by adding columns (in other words, joining on the row index values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5     0     1     2\n",
      "0   0   1   2   3   4   5   0.0   1.0   2.0\n",
      "1   6   7   8   9  10  11   3.0   4.0   5.0\n",
      "2  12  13  14  15  16  17   6.0   7.0   8.0\n",
      "3  18  19  20  21  22  23   9.0  10.0  11.0\n",
      "4  24  25  26  27  28  29  12.0  13.0  14.0\n",
      "5  30  31  32  33  34  35   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "joined = pd.concat([DF_obj3, DF_obj_4], axis =1) \n",
    "\n",
    "print(joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n",
      "    0   1   2\n",
      "0   0   1   2\n",
      "1   3   4   5\n",
      "2   6   7   8\n",
      "3   9  10  11\n",
      "4  12  13  14\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj3) \n",
    "print(DF_obj_4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming data  and Dropping data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj3) \n",
    "drp =DF_obj3.drop([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n"
     ]
    }
   ],
   "source": [
    "print(drp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop2 = DF_obj3.drop([0,2], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5\n",
      "0   0   1   2   3   4   5\n",
      "1   6   7   8   9  10  11\n",
      "2  12  13  14  15  16  17\n",
      "3  18  19  20  21  22  23\n",
      "4  24  25  26  27  28  29\n",
      "5  30  31  32  33  34  35\n"
     ]
    }
   ],
   "source": [
    "print(DF_obj3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         3         4         5\n",
      "0 -0.673210 -0.541845 -0.352464  1.688785\n",
      "1  1.121011  0.872053 -1.142141       NaN\n",
      "2 -0.177927 -0.289260 -0.904782       NaN\n",
      "3  0.649388 -0.977803 -1.972866       NaN\n",
      "4 -3.049890 -1.947339  0.533330  0.379163\n",
      "5  0.307235 -0.196576  0.922861  1.727249\n"
     ]
    }
   ],
   "source": [
    "series_obj = Series(np.arange(6)) \n",
    "series_obj.name = \"added_variable\" \n",
    "print(DF_obj.drop([0,2], axis=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use .join() method to join two data sources into one. The .join() method works by joining the two sources on their row index values: variable_added = DataFrame.join(DF_obj, series_obj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting data \n",
    "## To sort rows in a DataFrame, either in ascending or descending order, call the .sort_values()  # method off of the DataFrame, and pass in the by argument to specify the column index upon which the DataFrame should be sorted.  \n",
    "#### DF_sorted = DF_obj.sort_values(by=[5], ascending=[False]) print(DF_sorted) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and data aggregation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filepath = 'mtcars.csv' cars = pd.read_csv(filepath) cars.columns = ['car_names','mpg','cyl','disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb'] print(cars.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
